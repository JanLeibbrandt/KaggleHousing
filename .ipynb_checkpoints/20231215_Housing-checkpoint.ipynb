{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('house-prices-advanced-regression-techniques/train.csv', delimiter=',')\n",
    "test_data = pd.read_csv('house-prices-advanced-regression-techniques/test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical variable splitting\n",
    "\n",
    "Needs to be done before splitting the data in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_split = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'MoSold', 'SaleType', 'SaleCondition']\n",
    "\n",
    "def category_splitting(dataframe_to_split, features_to_split):\n",
    "    \n",
    "    dummy_table = dataframe_to_split['Id']\n",
    "\n",
    "    for column in features_to_split:\n",
    "        dataframe_to_split[column].fillna(\"None\", inplace = True)\n",
    "        split_by_category = pd.get_dummies(dataframe_to_split[column], prefix = column)\n",
    "        dummy_table = pd.concat([dummy_table, split_by_category], axis='columns')\n",
    "    \n",
    "    dataframe_to_split.drop(columns = features_to_split, inplace = True)\n",
    "    dummy_table.drop(columns = ['Id'], inplace = True)\n",
    "    \n",
    "\n",
    "    dataframe_to_split = pd.concat([dataframe_to_split, dummy_table], axis='columns')\n",
    "    \n",
    "    return dataframe_to_split\n",
    "\n",
    "\n",
    "raw_data_split = category_splitting(raw_data, features_to_split)\n",
    "test_data_split = category_splitting(test_data, features_to_split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineer some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data_split['has_2nd_floor'] = np.where(raw_data_split['2ndFlrSF'] > 0, 1, 0)\n",
    "raw_data_split['has_lowQF'] = np.where(raw_data_split['LowQualFinSF'] > 0, 1, 0)\n",
    "raw_data_split['has_2ormorebath'] = np.where(raw_data_split['FullBath'] > 1, 1, 0)\n",
    "raw_data_split['has_fireplace'] = np.where(raw_data_split['Fireplaces'] > 0, 1, 0)\n",
    "raw_data_split['has_wood_deck'] = np.where(raw_data_split['WoodDeckSF']  > 0, 1, 0)\n",
    "raw_data_split['has_open_porch'] = np.where(raw_data_split['OpenPorchSF'] > 0, 1, 0)\n",
    "raw_data_split['has_enclosed_porch'] = np.where(raw_data_split['EnclosedPorch'] > 0, 1, 0)\n",
    "raw_data_split['has_3Ssn_porch'] = np.where(raw_data_split['3SsnPorch'] > 0, 1, 0)\n",
    "raw_data_split['has_screen_porch'] = np.where(raw_data_split['ScreenPorch'] > 0, 1, 0)\n",
    "raw_data_split['built_last_1Y'] = np.where(raw_data_split['YearBuilt'] > 2008, 1, 0)\n",
    "raw_data_split['built_last_5Y'] = np.where(raw_data_split['YearBuilt'] > 2004, 1, 0)\n",
    "raw_data_split['built_last_10Y'] = np.where(raw_data_split['YearBuilt'] > 1998, 1, 0)\n",
    "\n",
    "\n",
    "test_data_split['has_2nd_floor'] = np.where(test_data_split['2ndFlrSF'] > 0, 1, 0)\n",
    "test_data_split['has_lowQF'] = np.where(test_data_split['LowQualFinSF'] > 0, 1, 0)\n",
    "test_data_split['has_2ormorebath'] = np.where(test_data_split['FullBath'] > 1, 1, 0)\n",
    "test_data_split['has_fireplace'] = np.where(test_data_split['Fireplaces'] > 0, 1, 0)\n",
    "test_data_split['has_wood_deck'] = np.where(test_data_split['WoodDeckSF'] > 0, 1, 0)\n",
    "test_data_split['has_open_porch'] = np.where(test_data_split['OpenPorchSF'] > 0, 1, 0)\n",
    "test_data_split['has_enclosed_porch'] = np.where(test_data_split['EnclosedPorch'] > 0, 1, 0)\n",
    "test_data_split['has_3Ssn_porch'] = np.where(test_data_split['3SsnPorch'] > 0, 1, 0)\n",
    "test_data_split['has_screen_porch'] = np.where(test_data_split['ScreenPorch'] > 0, 1, 0)\n",
    "test_data_split['built_last_1Y'] = np.where(test_data_split['YearBuilt'] > 2008, 1, 0)\n",
    "test_data_split['built_last_5Y'] = np.where(test_data_split['YearBuilt'] > 2004, 1, 0)\n",
    "test_data_split['built_last_10Y'] = np.where(test_data_split['YearBuilt'] > 1998, 1, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure overlap between categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 323)\n",
      "(1459, 323)\n"
     ]
    }
   ],
   "source": [
    "raw_categories = raw_data_split.columns\n",
    "test_categories = test_data_split.columns\n",
    "\n",
    "def intersection(list_a, list_b):\n",
    "    return [ e for e in list_a if e in list_b ]\n",
    "\n",
    "def only_in_1_not_in_2(list_a, list_b):\n",
    "    return [ e for e in list_a if e not in list_b ]\n",
    "\n",
    "overlap = intersection(raw_categories, test_categories)\n",
    "overlap_with_output = copy.deepcopy(overlap)\n",
    "overlap_with_output.append('SalePrice')\n",
    "\n",
    "only_in_train = only_in_1_not_in_2(raw_categories, test_categories)\n",
    "\n",
    "raw_data_split = raw_data_split[overlap_with_output]\n",
    "test_data_split = test_data_split[overlap]\n",
    "test_data_split['SalePrice']=-1\n",
    "\n",
    "print(raw_data_split.shape)\n",
    "print(test_data_split.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling and adding squares and cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(col):\n",
    "    if col.dtype == 'int64' or col.dtype == 'float64':\n",
    "        mean = col.mean()\n",
    "        std_dev = col.std()\n",
    "        col = (col-mean)/std_dev\n",
    "        \n",
    "    return col\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = ['LotFrontage', 'LotArea', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'GrLivArea', 'PoolArea', 'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'KitchenAbvGr', 'YrSold', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'MiscVal']\n",
    "\n",
    "def scale_features(dataframe_to_scale, features_to_scale):\n",
    "    \n",
    "    for column in features_to_scale:\n",
    "        dataframe_to_scale[column] = scale_data(dataframe_to_scale[column])\n",
    "        \n",
    "        square_name = column + \"_squared\"\n",
    "        cube_name = column + \"_cubed\"\n",
    "        quad_name = column + \"_sqrt\"\n",
    "        log_name = column + \"_log\"\n",
    "        dataframe_to_scale[square_name] = scale_data(dataframe_to_scale[column]**2)\n",
    "        dataframe_to_scale[cube_name] = scale_data(dataframe_to_scale[column]**3)\n",
    "        dataframe_to_scale[quad_name] = scale_data(dataframe_to_scale[column]**(1/2))\n",
    "        dataframe_to_scale[log_name] = scale_data(np.log(dataframe_to_scale[column]+0.01))\n",
    "\n",
    "        \n",
    "    dataframe_to_scale.fillna(0, inplace = True)\n",
    "\n",
    "    return dataframe_to_scale\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_split.drop([523, 1298], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:726: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dataframe_to_normalize = pd.concat([raw_data_split, test_data_split], axis='rows')\n",
    "\n",
    "dataframe_normalized = scale_features(dataframe_to_normalize, features_to_scale)\n",
    "\n",
    "cleaned_train_data = dataframe_normalized[:1458]\n",
    "test_data_split = dataframe_normalized[1458:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 459)\n",
      "(1459, 459)\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_train_data.shape)\n",
    "print(test_data_split.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_output = cleaned_train_data['SalePrice']\n",
    "train_data_features = cleaned_train_data.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "test_data_features_for_submission = test_data_split.drop(['SalePrice', 'Id'], axis = 1)\n",
    "# test_data_features_for_submission.to_csv('20231213_train_data2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(w, b, x, y, lambda_ = 1):\n",
    "    m, n = x.shape\n",
    "    fx = np.dot(x, w) + b\n",
    "    cost = (fx - y)**2\n",
    "    cost = np.sum(cost)/(2*m)\n",
    "    \n",
    "    regularization_term = w**2\n",
    "    regularization_term = np.sum(regularization_term)/(2*m)*lambda_\n",
    "    return cost + regularization_term\n",
    "    \n",
    "\n",
    "def compute_gradient(w, b, x, y, lambda_ = 1):\n",
    "    m, n = x.shape\n",
    "    fx = np.dot(x, w) + b\n",
    "    \n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0\n",
    "    \n",
    "    err = (fx-y)\n",
    "    dj_dw = np.dot(err,x)/m + lambda_*w/m\n",
    "    \n",
    "    dj_db = np.sum(fx-y)/m\n",
    "    \n",
    "    return dj_dw, dj_db\n",
    "\n",
    "\n",
    "def gradient_descent(w_in, b, x, y, alpha, iterations, lambda_):\n",
    "    \n",
    "    cost = 10000000000000000\n",
    "    w = copy.deepcopy(w_in)\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        dj_dw, dj_db = compute_gradient(w, b, x, y, lambda_)\n",
    "        w_new = w - alpha*dj_dw\n",
    "        b_new = b - alpha*dj_db\n",
    "        \n",
    "        w = w_new\n",
    "        b = b_new\n",
    "        \n",
    "        new_cost = compute_cost(w_new, b_new, x, y)\n",
    "        \n",
    "        if iteration%1000==0: \n",
    "            print(f\"iteration: {iteration} cost: {cost/1000000:.2f}\")\n",
    "            \n",
    "        if iteration%100==0: \n",
    "            if new_cost > cost: break\n",
    "\n",
    "        cost = new_cost\n",
    "    return (w_new, b_new)\n",
    "\n",
    "    \n",
    "def make_prediction(w, b, features):\n",
    "    fx = np.dot(features, w) + b\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv (w, b, x, y, alpha, iterations, lambda_, k):\n",
    "    \n",
    "    cost_cv = 0\n",
    "\n",
    "    for i in range(k):\n",
    "        \n",
    "        x_train = x.iloc[lambda x: (x.index+i) % k != 0,]\n",
    "        y_train = y.iloc[lambda x: (x.index+i) % k != 0,]\n",
    "        x_test = x.iloc[lambda x: (x.index+i) % k == 0,]\n",
    "        y_test = y.iloc[lambda x: (x.index+i) % k == 0,]   \n",
    "        \n",
    "        w_computed, b_computed = gradient_descent(w, b, x_train, y_train, alpha, iterations, lambda_)\n",
    "        cost_prediction = compute_cost(w_computed, b_computed, x_test, y_test, 0)\n",
    "        \n",
    "        '''\n",
    "        if i == 2:\n",
    "            prediction = make_prediction(w_computed, b_computed, x_test)\n",
    "            difference = abs(prediction - y_test)\n",
    "            print(f\"difference: {difference[difference > 100000]}\")\n",
    "        '''\n",
    "        print(f\"cost prediction for round {i} is {cost_prediction/1000000:.2f}\")\n",
    "        cost_cv += cost_prediction\n",
    "        \n",
    "    return cost_cv/k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run gradient descent and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 cost: 10000000000.00\n",
      "iteration: 1000 cost: 189.28\n",
      "iteration: 2000 cost: 188.02\n",
      "iteration: 3000 cost: 187.32\n",
      "iteration: 4000 cost: 186.96\n",
      "iteration: 5000 cost: 186.78\n",
      "iteration: 6000 cost: 186.72\n",
      "cost prediction for round 0 is 221.31\n",
      "iteration: 0 cost: 10000000000.00\n",
      "iteration: 1000 cost: 181.74\n",
      "iteration: 2000 cost: 180.32\n",
      "iteration: 3000 cost: 179.51\n",
      "iteration: 4000 cost: 179.04\n",
      "iteration: 5000 cost: 178.78\n",
      "iteration: 6000 cost: 178.64\n",
      "iteration: 7000 cost: 178.58\n",
      "iteration: 8000 cost: 178.56\n",
      "cost prediction for round 1 is 227.17\n",
      "iteration: 0 cost: 10000000000.00\n",
      "iteration: 1000 cost: 151.80\n",
      "iteration: 2000 cost: 150.44\n",
      "iteration: 3000 cost: 149.67\n",
      "iteration: 4000 cost: 149.24\n",
      "iteration: 5000 cost: 149.01\n",
      "iteration: 6000 cost: 148.90\n",
      "iteration: 7000 cost: 148.86\n",
      "cost prediction for round 2 is 428.83\n",
      "iteration: 0 cost: 10000000000.00\n",
      "iteration: 1000 cost: 192.31\n",
      "iteration: 2000 cost: 190.74\n",
      "iteration: 3000 cost: 189.81\n",
      "iteration: 4000 cost: 189.26\n",
      "iteration: 5000 cost: 188.94\n",
      "iteration: 6000 cost: 188.76\n",
      "iteration: 7000 cost: 188.66\n",
      "iteration: 8000 cost: 188.62\n",
      "iteration: 9000 cost: 188.60\n",
      "cost prediction for round 3 is 187.77\n",
      "iteration: 0 cost: 10000000000.00\n",
      "iteration: 1000 cost: 185.14\n",
      "iteration: 2000 cost: 183.80\n",
      "iteration: 3000 cost: 183.04\n",
      "iteration: 4000 cost: 182.62\n",
      "iteration: 5000 cost: 182.40\n",
      "iteration: 6000 cost: 182.30\n",
      "iteration: 7000 cost: 182.27\n",
      "cost prediction for round 4 is 253.33\n",
      "cost: 263.68\n"
     ]
    }
   ],
   "source": [
    "b = 0\n",
    "w = np.zeros(train_data_features.shape[1])\n",
    "alpha = 0.06\n",
    "iterations = 10000\n",
    "lambda_ = 100\n",
    "k = 5\n",
    "\n",
    "cost_final = run_cv(w, b, train_data_features, train_data_output, alpha, iterations, lambda_, k)\n",
    "\n",
    "print(f\"cost: {cost_final/1000000:.2f}\")\n",
    "\n",
    "\n",
    "# lambda 150   iter 7000  alpha 0.06  cost 266.96\n",
    "# lambda 140   iter 7000  alpha 0.06  cost 266.24\n",
    "# lambda 130   iter 7000  alpha 0.06  cost 265.52\n",
    "# lambda 120   iter 7000  alpha 0.06  cost 264.90\n",
    "# lambda 120   iter 7000  alpha 0.06  cost 263.68\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create output file for submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 cost: 10000000000.00\n",
      "iteration: 1000 cost: 192.97\n",
      "iteration: 2000 cost: 191.31\n",
      "iteration: 3000 cost: 190.44\n",
      "iteration: 4000 cost: 190.00\n",
      "iteration: 5000 cost: 189.80\n",
      "iteration: 6000 cost: 189.72\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 150\n",
    "\n",
    "w_computed, b_computed = gradient_descent(w, b, train_data_features, train_data_output, alpha, iterations, lambda_)\n",
    "\n",
    "prediction = make_prediction(w_computed, b_computed, test_data_features_for_submission)\n",
    "\n",
    "submission_file = pd.concat([test_data['Id'],pd.DataFrame(prediction)], axis = 1)\n",
    "submission_file.columns = ['Id', 'SalePrice']\n",
    "submission_file.to_csv('20231214_submission3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
